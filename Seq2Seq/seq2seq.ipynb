{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11076550,"sourceType":"datasetVersion","datasetId":6903351}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from collections.abc import Callable\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nimport torch","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-19T15:28:43.642905Z","iopub.execute_input":"2025-03-19T15:28:43.643268Z","iopub.status.idle":"2025-03-19T15:28:43.647070Z","shell.execute_reply.started":"2025-03-19T15:28:43.643238Z","shell.execute_reply":"2025-03-19T15:28:43.646261Z"}},"outputs":[],"execution_count":55},{"cell_type":"code","source":"import pandas as pd\n\neng_ger = pd.read_csv(\"/kaggle/input/eng2ger/english_german.csv\")\n\neng_ger.head(20)[10:]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T15:28:43.648270Z","iopub.execute_input":"2025-03-19T15:28:43.648508Z","iopub.status.idle":"2025-03-19T15:28:43.895242Z","shell.execute_reply.started":"2025-03-19T15:28:43.648487Z","shell.execute_reply":"2025-03-19T15:28:43.894460Z"}},"outputs":[{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"   English             German\n10   hello              hallo\n11   i try    ich probiere es\n12   i won   ich hab gewonnen\n13   i won  ich habe gewonnen\n14   smile            lacheln\n15  cheers           zum wohl\n16  freeze     keine bewegung\n17  freeze      stehenbleiben\n18  got it         verstanden\n19  got it      einverstanden","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>English</th>\n      <th>German</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>10</th>\n      <td>hello</td>\n      <td>hallo</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>i try</td>\n      <td>ich probiere es</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>i won</td>\n      <td>ich hab gewonnen</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>i won</td>\n      <td>ich habe gewonnen</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>smile</td>\n      <td>lacheln</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>cheers</td>\n      <td>zum wohl</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>freeze</td>\n      <td>keine bewegung</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>freeze</td>\n      <td>stehenbleiben</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>got it</td>\n      <td>verstanden</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>got it</td>\n      <td>einverstanden</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":56},{"cell_type":"code","source":"# eng_ger = eng_ger.head(100)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T15:28:43.896663Z","iopub.execute_input":"2025-03-19T15:28:43.896889Z","iopub.status.idle":"2025-03-19T15:28:43.900272Z","shell.execute_reply.started":"2025-03-19T15:28:43.896869Z","shell.execute_reply":"2025-03-19T15:28:43.899414Z"}},"outputs":[],"execution_count":57},{"cell_type":"code","source":"eng_ger[\"English\"] = \"<sos> \" + eng_ger[\"English\"].str.strip() + \" <eos>\"\neng_ger[\"German\"] = \"<sos> \" + eng_ger[\"German\"].str.strip() + \" <eos>\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T15:28:43.901463Z","iopub.execute_input":"2025-03-19T15:28:43.901718Z","iopub.status.idle":"2025-03-19T15:28:44.042995Z","shell.execute_reply.started":"2025-03-19T15:28:43.901698Z","shell.execute_reply":"2025-03-19T15:28:44.042105Z"}},"outputs":[],"execution_count":58},{"cell_type":"code","source":"eng_ger.head(20)[10:]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T15:28:44.043899Z","iopub.execute_input":"2025-03-19T15:28:44.044198Z","iopub.status.idle":"2025-03-19T15:28:44.052621Z","shell.execute_reply.started":"2025-03-19T15:28:44.044168Z","shell.execute_reply":"2025-03-19T15:28:44.051677Z"}},"outputs":[{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"               English                         German\n10   <sos> hello <eos>              <sos> hallo <eos>\n11   <sos> i try <eos>    <sos> ich probiere es <eos>\n12   <sos> i won <eos>   <sos> ich hab gewonnen <eos>\n13   <sos> i won <eos>  <sos> ich habe gewonnen <eos>\n14   <sos> smile <eos>            <sos> lacheln <eos>\n15  <sos> cheers <eos>           <sos> zum wohl <eos>\n16  <sos> freeze <eos>     <sos> keine bewegung <eos>\n17  <sos> freeze <eos>      <sos> stehenbleiben <eos>\n18  <sos> got it <eos>         <sos> verstanden <eos>\n19  <sos> got it <eos>      <sos> einverstanden <eos>","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>English</th>\n      <th>German</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>10</th>\n      <td>&lt;sos&gt; hello &lt;eos&gt;</td>\n      <td>&lt;sos&gt; hallo &lt;eos&gt;</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>&lt;sos&gt; i try &lt;eos&gt;</td>\n      <td>&lt;sos&gt; ich probiere es &lt;eos&gt;</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>&lt;sos&gt; i won &lt;eos&gt;</td>\n      <td>&lt;sos&gt; ich hab gewonnen &lt;eos&gt;</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>&lt;sos&gt; i won &lt;eos&gt;</td>\n      <td>&lt;sos&gt; ich habe gewonnen &lt;eos&gt;</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>&lt;sos&gt; smile &lt;eos&gt;</td>\n      <td>&lt;sos&gt; lacheln &lt;eos&gt;</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>&lt;sos&gt; cheers &lt;eos&gt;</td>\n      <td>&lt;sos&gt; zum wohl &lt;eos&gt;</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>&lt;sos&gt; freeze &lt;eos&gt;</td>\n      <td>&lt;sos&gt; keine bewegung &lt;eos&gt;</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>&lt;sos&gt; freeze &lt;eos&gt;</td>\n      <td>&lt;sos&gt; stehenbleiben &lt;eos&gt;</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>&lt;sos&gt; got it &lt;eos&gt;</td>\n      <td>&lt;sos&gt; verstanden &lt;eos&gt;</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>&lt;sos&gt; got it &lt;eos&gt;</td>\n      <td>&lt;sos&gt; einverstanden &lt;eos&gt;</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":59},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\nen_tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n')\nger_tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T15:28:44.053527Z","iopub.execute_input":"2025-03-19T15:28:44.053840Z","iopub.status.idle":"2025-03-19T15:28:44.076755Z","shell.execute_reply.started":"2025-03-19T15:28:44.053809Z","shell.execute_reply":"2025-03-19T15:28:44.075940Z"}},"outputs":[],"execution_count":60},{"cell_type":"code","source":"en_tokenizer.fit_on_texts(eng_ger[\"English\"])\nger_tokenizer.fit_on_texts(eng_ger[\"German\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T15:28:44.077693Z","iopub.execute_input":"2025-03-19T15:28:44.077992Z","iopub.status.idle":"2025-03-19T15:28:47.392288Z","shell.execute_reply.started":"2025-03-19T15:28:44.077950Z","shell.execute_reply":"2025-03-19T15:28:47.391619Z"}},"outputs":[],"execution_count":61},{"cell_type":"code","source":"english = en_tokenizer.texts_to_sequences(eng_ger[\"English\"])\ngerman = ger_tokenizer.texts_to_sequences(eng_ger[\"German\"])\n\nprint(english[:10])\nprint(german[:10])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T15:28:47.393103Z","iopub.execute_input":"2025-03-19T15:28:47.393376Z","iopub.status.idle":"2025-03-19T15:28:50.279895Z","shell.execute_reply.started":"2025-03-19T15:28:47.393347Z","shell.execute_reply":"2025-03-19T15:28:50.278874Z"}},"outputs":[{"name":"stdout","text":"[[1, 3260, 2], [1, 3260, 2], [1, 462, 2], [1, 4151, 2], [1, 4151, 2], [1, 444, 2], [1, 79, 2], [1, 79, 2], [1, 219, 2], [1, 272, 2]]\n[[1, 2207, 2], [1, 3781, 1525, 2], [1, 5262, 2], [1, 9957, 2], [1, 16860, 2], [1, 645, 2], [1, 211, 2], [1, 10, 16861, 2], [1, 12301, 2], [1, 781, 2]]\n","output_type":"stream"}],"execution_count":62},{"cell_type":"code","source":"english = pad_sequences(english, padding='post')\ngerman = pad_sequences(german, padding='post')\n\nprint(english[:10])\nprint(german[:10])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T15:28:50.282991Z","iopub.execute_input":"2025-03-19T15:28:50.283238Z","iopub.status.idle":"2025-03-19T15:28:50.990620Z","shell.execute_reply.started":"2025-03-19T15:28:50.283215Z","shell.execute_reply":"2025-03-19T15:28:50.989589Z"}},"outputs":[{"name":"stdout","text":"[[   1 3260    2    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0]\n [   1 3260    2    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0]\n [   1  462    2    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0]\n [   1 4151    2    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0]\n [   1 4151    2    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0]\n [   1  444    2    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0]\n [   1   79    2    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0]\n [   1   79    2    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0]\n [   1  219    2    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0]\n [   1  272    2    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0]]\n[[    1  2207     2     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0     0     0]\n [    1  3781  1525     2     0     0     0     0     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0     0     0]\n [    1  5262     2     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0     0     0]\n [    1  9957     2     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0     0     0]\n [    1 16860     2     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0     0     0]\n [    1   645     2     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0     0     0]\n [    1   211     2     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0     0     0]\n [    1    10 16861     2     0     0     0     0     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0     0     0]\n [    1 12301     2     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0     0     0]\n [    1   781     2     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0     0     0]]\n","output_type":"stream"}],"execution_count":63},{"cell_type":"code","source":"print(len(english))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T15:28:50.992205Z","iopub.execute_input":"2025-03-19T15:28:50.992549Z","iopub.status.idle":"2025-03-19T15:28:50.997164Z","shell.execute_reply.started":"2025-03-19T15:28:50.992515Z","shell.execute_reply":"2025-03-19T15:28:50.996192Z"}},"outputs":[{"name":"stdout","text":"152820\n","output_type":"stream"}],"execution_count":64},{"cell_type":"code","source":"test_size = 0.2\ntrain_len = int((1-test_size)*len(english))\nXtrain, Xtest, ytrain, ytest = english[:train_len], english[train_len:], german[:train_len], german[train_len:]\n\nprint(len(Xtrain))\nprint(len(Xtest))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T15:28:50.998177Z","iopub.execute_input":"2025-03-19T15:28:50.998474Z","iopub.status.idle":"2025-03-19T15:28:51.012158Z","shell.execute_reply.started":"2025-03-19T15:28:50.998441Z","shell.execute_reply":"2025-03-19T15:28:51.011256Z"}},"outputs":[{"name":"stdout","text":"122256\n30564\n","output_type":"stream"}],"execution_count":65},{"cell_type":"code","source":"class dataset(Dataset):\n    def __init__(self, english, german):\n        self.en = english\n        self.ger = german\n    def __len__(self):\n        return len(self.en)\n    def __getitem__(self, idx):\n        x = self.en[idx]\n        y = self.ger[idx]\n        return torch.tensor(x, dtype=torch.long),torch.tensor(y, dtype=torch.long)\n\ntrain_loader = DataLoader(dataset=dataset(Xtrain, ytrain), batch_size=256, num_workers=4, shuffle=True)\ntest_loader = DataLoader(dataset=dataset(Xtest, ytest), batch_size=256, num_workers=4, shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T15:28:51.013024Z","iopub.execute_input":"2025-03-19T15:28:51.013306Z","iopub.status.idle":"2025-03-19T15:28:51.028407Z","shell.execute_reply.started":"2025-03-19T15:28:51.013274Z","shell.execute_reply":"2025-03-19T15:28:51.027551Z"}},"outputs":[],"execution_count":66},{"cell_type":"code","source":"for i, dat in enumerate(train_loader):\n    print(dat)\n    if i == 1:\n        break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T15:28:51.029177Z","iopub.execute_input":"2025-03-19T15:28:51.029460Z","iopub.status.idle":"2025-03-19T15:28:51.282747Z","shell.execute_reply.started":"2025-03-19T15:28:51.029433Z","shell.execute_reply":"2025-03-19T15:28:51.281516Z"}},"outputs":[{"name":"stdout","text":"[tensor([[  1,  15,   5,  ...,   0,   0,   0],\n        [  1,   7, 142,  ...,   0,   0,   0],\n        [  1, 217, 188,  ...,   0,   0,   0],\n        ...,\n        [  1,  26, 218,  ...,   0,   0,   0],\n        [  1,  72, 374,  ...,   0,   0,   0],\n        [  1, 334, 324,  ...,   0,   0,   0]]), tensor([[   1,  596,    8,  ...,    0,    0,    0],\n        [   1,    4,   16,  ...,    0,    0,    0],\n        [   1,  109,    5,  ...,    0,    0,    0],\n        ...,\n        [   1,   77,  191,  ...,    0,    0,    0],\n        [   1,    8,   70,  ...,    0,    0,    0],\n        [   1, 1116,  267,  ...,    0,    0,    0]])]\n[tensor([[    1,    49,   365,  ...,     0,     0,     0],\n        [    1,     6,   672,  ...,     0,     0,     0],\n        [    1,    15,    74,  ...,     0,     0,     0],\n        ...,\n        [    1,    26, 11845,  ...,     0,     0,     0],\n        [    1,    22,   170,  ...,     0,     0,     0],\n        [    1,   141,    35,  ...,     0,     0,     0]]), tensor([[   1,   12,    5,  ...,    0,    0,    0],\n        [   1,    3, 2868,  ...,    0,    0,    0],\n        [   1,  496,    6,  ...,    0,    0,    0],\n        ...,\n        [   1,   77, 9391,  ...,    0,    0,    0],\n        [   1, 2568,    6,  ...,    0,    0,    0],\n        [   1,    3,   52,  ...,    0,    0,    0]])]\n","output_type":"stream"}],"execution_count":67},{"cell_type":"code","source":"en_vocab_size = len(en_tokenizer.word_index)\nger_vocab_size = len(ger_tokenizer.word_index)\n\nprint(en_vocab_size)\nprint(ger_vocab_size)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T15:28:51.283910Z","iopub.execute_input":"2025-03-19T15:28:51.284263Z","iopub.status.idle":"2025-03-19T15:28:51.290146Z","shell.execute_reply.started":"2025-03-19T15:28:51.284229Z","shell.execute_reply":"2025-03-19T15:28:51.289073Z"}},"outputs":[{"name":"stdout","text":"14850\n30945\n","output_type":"stream"}],"execution_count":68},{"cell_type":"code","source":"import random\nclass Encoder(nn.Module):\n    def __init__(self, vocab_size:int, embed_size:int, hidden_size:int):\n        super().__init__()\n        self.vocab_size = vocab_size\n        self.embed_size = embed_size\n        self.hidden_size = hidden_size\n        self.embedding = nn.Embedding(vocab_size, embed_size, padding_idx=0)\n        self.LSTM = nn.LSTM(input_size=embed_size, hidden_size=hidden_size, batch_first=True, num_layers=2, bidirectional=True)\n    def forward(self, x):\n        # (batch, seq)\n        embedding = self.embedding(x)\n        # (batch, seq, embed_size)\n        outputs, (hn, cn) = self.LSTM(embedding)\n        # outputs: (batch, seq, hidden_size),  hn/cn : (num_layers, batch, hidden_size)\n        return hn, cn\nclass Decoder(nn.Module):\n    def __init__(self, vocab_size:int, embed_size:int, hidden_size:int):\n        super().__init__()\n        self.vocab_size = vocab_size\n        self.embed_size = embed_size\n        self.hidden_size = hidden_size\n        self.embedding = nn.Embedding(vocab_size, embed_size, padding_idx=0)\n        self.LSTM = nn.LSTM(input_size=embed_size, hidden_size=hidden_size, batch_first=True, num_layers=4)\n        self.linear = nn.Linear(hidden_size, vocab_size)\n\n    def forward(self, x, hn, cn): # x is last english word\n        # x: (batch,)\n        x = x.unsqueeze(1)\n        # x: (batch, 1) -- making it a sequence of length 1 so as to be consistent when passing to LSTM\n        embedding = self.embedding(x)\n        # embedding: (batch, 1, embed_size)\n        outputs, (hn, cn) = self.LSTM(embedding, (hn, cn))\n        # hn/cn : (batch, hidden_size)\n        # outputs: (batch, 1, hidden_size) -- since only recieves one token at a time\n        predictions = self.linear(outputs)\n        # predictions: (batch, 1, vocab_size)\n        return predictions.squeeze(1), hn, cn # predictions: (batch, vocab_size)\n\nclass seq2seq(nn.Module):\n    def __init__(self, en_vocab_size:int, ger_vocab_size:int, embed_size:int, hidden_size:int):\n        super().__init__()\n        self.en_vocab_size = en_vocab_size\n        self.ger_vocab_size = ger_vocab_size\n        # plus 1 for empty/blank token\n        self.encoder = Encoder(en_vocab_size, embed_size, hidden_size)\n        self.decoder = Decoder(ger_vocab_size, embed_size, hidden_size)\n    \n    def forward(self, x, y, epoch):\n        hn, cn = self.encoder(x)\n        # y: (batch_size, seq_size)\n        batch_size = y.shape[0] # int\n        target_len = y.shape[1] # int -> output sequence length\n        token = y[:,0] # (batch,)\n        outputs = torch.zeros(batch_size, target_len, self.ger_vocab_size, device=next(self.parameters()).device) # (batch, seq, vocab_size)\n        outputs[:, 0, 1] = 1\n        for i in range(1, target_len):\n            predictions, hn, cn = self.decoder(token, hn, cn) # (batch, vocab_size)\n            token = y[:, i] if random.random() < 0.5/(epoch+1) else predictions.argmax(dim=-1)\n            outputs[:,i] = predictions # outputs[:,i] has the same shape as outputs[:, i, :] which is (batch, vocab_size)\n        return outputs # (batch, seq, vocab_size)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T15:28:51.291242Z","iopub.execute_input":"2025-03-19T15:28:51.291468Z","iopub.status.idle":"2025-03-19T15:28:51.307509Z","shell.execute_reply.started":"2025-03-19T15:28:51.291448Z","shell.execute_reply":"2025-03-19T15:28:51.306732Z"}},"outputs":[],"execution_count":69},{"cell_type":"code","source":"from tqdm import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T15:28:51.308397Z","iopub.execute_input":"2025-03-19T15:28:51.308725Z","iopub.status.idle":"2025-03-19T15:28:51.325422Z","shell.execute_reply.started":"2025-03-19T15:28:51.308695Z","shell.execute_reply":"2025-03-19T15:28:51.324552Z"}},"outputs":[],"execution_count":70},{"cell_type":"code","source":"output = \"/kaggle/working/weights.pt\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T15:28:51.326242Z","iopub.execute_input":"2025-03-19T15:28:51.326479Z","iopub.status.idle":"2025-03-19T15:28:51.340137Z","shell.execute_reply.started":"2025-03-19T15:28:51.326459Z","shell.execute_reply":"2025-03-19T15:28:51.339185Z"}},"outputs":[],"execution_count":71},{"cell_type":"code","source":"def fit(train_loader, test_loader, model:Callable, optimizer:Callable, loss_fn:Callable, epochs:int, device:torch.device):\n    model.train()\n    epoch_seq = list(range(1, epochs+1))\n    for epoch in range(epochs):\n        en_sentence = \"who are you\"\n        loop = tqdm(enumerate(train_loader), total=len(train_loader))\n        for batch, (x,y) in loop:\n            x,y = x.to(device), y.to(device)\n            optimizer.zero_grad()\n            y_pred = model(x, y, epoch) \n            # y_pred: (batch, seq, vocab_size) | y: (batch, seq)\n            y_pred = y_pred.reshape(-1, y_pred.shape[2]) # (batch * seq, vocab_size)\n            y = y.reshape(-1) # (batch * seq,)\n            loss = loss_fn(y_pred, y)\n            loss.backward()\n            optimizer.step()\n            loop.set_description(f\"EPOCH: {epoch+1}/{epochs}\")\n            correct = (y==y_pred.argmax(dim=-1)).sum().item()\n            total = len(y)\n            loop.set_postfix(loss=loss.item(), acc=correct/total)\n        torch.save(model.state_dict(), output)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T15:28:51.341008Z","iopub.execute_input":"2025-03-19T15:28:51.341281Z","iopub.status.idle":"2025-03-19T15:28:51.360100Z","shell.execute_reply.started":"2025-03-19T15:28:51.341255Z","shell.execute_reply":"2025-03-19T15:28:51.359265Z"}},"outputs":[],"execution_count":72},{"cell_type":"code","source":"import os\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nif os.path.exists(output):\n    model = seq2seq(en_vocab_size=en_vocab_size, ger_vocab_size=ger_vocab_size, embed_size=256, hidden_size=128)\n    model.load_state_dict(torch.load(output))\nelse:\n    model = seq2seq(en_vocab_size=en_vocab_size, ger_vocab_size=ger_vocab_size, embed_size=256, hidden_size=128)\noptimizer = torch.optim.Adam(params=model.parameters())\nloss_fn = nn.CrossEntropyLoss()\nmodel.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T15:28:51.361005Z","iopub.execute_input":"2025-03-19T15:28:51.361283Z","iopub.status.idle":"2025-03-19T15:28:51.613423Z","shell.execute_reply.started":"2025-03-19T15:28:51.361254Z","shell.execute_reply":"2025-03-19T15:28:51.612447Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-73-1f9bad2e0fbb>:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(output))\n","output_type":"stream"},{"execution_count":73,"output_type":"execute_result","data":{"text/plain":"seq2seq(\n  (encoder): Encoder(\n    (embedding): Embedding(14850, 256, padding_idx=0)\n    (LSTM): LSTM(256, 128, num_layers=2, batch_first=True, bidirectional=True)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(30945, 256, padding_idx=0)\n    (LSTM): LSTM(256, 128, num_layers=4, batch_first=True)\n    (linear): Linear(in_features=128, out_features=30945, bias=True)\n  )\n)"},"metadata":{}}],"execution_count":73},{"cell_type":"code","source":"fit(train_loader=train_loader, test_loader=test_loader, model=model, optimizer=optimizer,loss_fn=loss_fn, epochs=10, device=device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T15:28:51.614446Z","iopub.execute_input":"2025-03-19T15:28:51.614766Z","iopub.status.idle":"2025-03-19T16:28:51.521385Z","shell.execute_reply.started":"2025-03-19T15:28:51.614733Z","shell.execute_reply":"2025-03-19T16:28:51.520494Z"}},"outputs":[{"name":"stderr","text":"EPOCH: 1/10: 100%|██████████| 478/478 [05:58<00:00,  1.33it/s, acc=0.938, loss=0.471]\nEPOCH: 2/10: 100%|██████████| 478/478 [05:59<00:00,  1.33it/s, acc=0.942, loss=0.454]\nEPOCH: 3/10: 100%|██████████| 478/478 [05:59<00:00,  1.33it/s, acc=0.94, loss=0.441] \nEPOCH: 4/10: 100%|██████████| 478/478 [05:59<00:00,  1.33it/s, acc=0.944, loss=0.434]\nEPOCH: 5/10: 100%|██████████| 478/478 [05:59<00:00,  1.33it/s, acc=0.94, loss=0.444] \nEPOCH: 6/10: 100%|██████████| 478/478 [05:59<00:00,  1.33it/s, acc=0.942, loss=0.424]\nEPOCH: 7/10: 100%|██████████| 478/478 [05:59<00:00,  1.33it/s, acc=0.939, loss=0.432]\nEPOCH: 8/10: 100%|██████████| 478/478 [05:59<00:00,  1.33it/s, acc=0.947, loss=0.388]\nEPOCH: 9/10: 100%|██████████| 478/478 [05:59<00:00,  1.33it/s, acc=0.948, loss=0.376]\nEPOCH: 10/10: 100%|██████████| 478/478 [05:59<00:00,  1.33it/s, acc=0.95, loss=0.379] \n","output_type":"stream"}],"execution_count":74},{"cell_type":"code","source":"model.to(\"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T16:28:51.522718Z","iopub.execute_input":"2025-03-19T16:28:51.523067Z","iopub.status.idle":"2025-03-19T16:28:51.624171Z","shell.execute_reply.started":"2025-03-19T16:28:51.523028Z","shell.execute_reply":"2025-03-19T16:28:51.623510Z"}},"outputs":[{"execution_count":75,"output_type":"execute_result","data":{"text/plain":"seq2seq(\n  (encoder): Encoder(\n    (embedding): Embedding(14850, 256, padding_idx=0)\n    (LSTM): LSTM(256, 128, num_layers=2, batch_first=True, bidirectional=True)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(30945, 256, padding_idx=0)\n    (LSTM): LSTM(256, 128, num_layers=4, batch_first=True)\n    (linear): Linear(in_features=128, out_features=30945, bias=True)\n  )\n)"},"metadata":{}}],"execution_count":75},{"cell_type":"code","source":"for x,y in train_loader:\n    print(y[0], y[0].shape)\n    break\n# <sos> german is token 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T16:28:51.624900Z","iopub.execute_input":"2025-03-19T16:28:51.625188Z","iopub.status.idle":"2025-03-19T16:28:51.838939Z","shell.execute_reply.started":"2025-03-19T16:28:51.625158Z","shell.execute_reply":"2025-03-19T16:28:51.838034Z"}},"outputs":[{"name":"stdout","text":"tensor([  1,  22,  16,   7, 330, 506, 128,   2,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]) torch.Size([55])\n","output_type":"stream"}],"execution_count":76},{"cell_type":"code","source":"def predict(model, x, target_len):\n    # x = x.to(device)\n    hn, cn = model.encoder(x)\n    # y: (batch_size, seq_size)\n    batch_size = x.shape[0] # int\n    token = torch.ones(batch_size, device=next(model.parameters()).device, dtype=torch.long) # (batch,) # <sos> token is 1\n    outputs = torch.zeros(batch_size, target_len, model.ger_vocab_size, device=next(model.parameters()).device)\n    outputs[:,0,1] = 1\n    for i in range(1, target_len):\n        predictions, hn, cn = model.decoder(token, hn, cn) # (batch, vocab_size)\n        outputs[:,i] = predictions # outputs[:,i] has the same shape as outputs[:, i, :] which is (batch, vocab_size)\n    return outputs # (batch, seq, vocab_size)\n\ndef translate(model, text:str):\n    print(text)\n    tokenized = en_tokenizer.texts_to_sequences([text])\n    padded_sequence = pad_sequences(tokenized, padding='post', maxlen=len(english[0]))\n    x = torch.tensor(padded_sequence)\n    predicted_sequence = predict(model, x, 7)\n    output_sequence = predicted_sequence[0].argmax(dim=-1).detach().cpu().numpy()\n    return ger_tokenizer.sequences_to_texts([output_sequence])[0]\n\nidx = 9\nprint(translate(model, eng_ger[\"English\"][idx]))\nprint()\nprint(\"original:\")\nprint(eng_ger[\"German\"][idx])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T16:28:51.840006Z","iopub.execute_input":"2025-03-19T16:28:51.840340Z","iopub.status.idle":"2025-03-19T16:28:51.876991Z","shell.execute_reply.started":"2025-03-19T16:28:51.840312Z","shell.execute_reply":"2025-03-19T16:28:51.876064Z"}},"outputs":[{"name":"stdout","text":"<sos> wait <eos>\n<sos> warte <eos> <eos>\n\noriginal:\n<sos> warte <eos>\n","output_type":"stream"}],"execution_count":77},{"cell_type":"code","source":"translate(model, \"<sos> got <eos>\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T16:28:51.877849Z","iopub.execute_input":"2025-03-19T16:28:51.878115Z","iopub.status.idle":"2025-03-19T16:28:51.902208Z","shell.execute_reply.started":"2025-03-19T16:28:51.878094Z","shell.execute_reply":"2025-03-19T16:28:51.901373Z"}},"outputs":[{"name":"stdout","text":"<sos> got <eos>\n","output_type":"stream"},{"execution_count":78,"output_type":"execute_result","data":{"text/plain":"'<sos> gehort <eos>'"},"metadata":{}}],"execution_count":78},{"cell_type":"code","source":"translate(model, \"<sos> you <eos>\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T16:41:55.703228Z","iopub.execute_input":"2025-03-19T16:41:55.703600Z","iopub.status.idle":"2025-03-19T16:41:55.728079Z","shell.execute_reply.started":"2025-03-19T16:41:55.703545Z","shell.execute_reply":"2025-03-19T16:41:55.727276Z"}},"outputs":[{"name":"stdout","text":"<sos> you <eos>\n","output_type":"stream"},{"execution_count":79,"output_type":"execute_result","data":{"text/plain":"'<sos> du sie <eos>'"},"metadata":{}}],"execution_count":79},{"cell_type":"code","source":"translate(model, \"<sos> how are you <eos>\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T16:42:08.677384Z","iopub.execute_input":"2025-03-19T16:42:08.677750Z","iopub.status.idle":"2025-03-19T16:42:08.705867Z","shell.execute_reply.started":"2025-03-19T16:42:08.677720Z","shell.execute_reply":"2025-03-19T16:42:08.704992Z"}},"outputs":[{"name":"stdout","text":"<sos> how are you <eos>\n","output_type":"stream"},{"execution_count":80,"output_type":"execute_result","data":{"text/plain":"'<sos> wie gehts dir <eos>'"},"metadata":{}}],"execution_count":80},{"cell_type":"code","source":"translate(model, \"<sos> what is your name? <eos>\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T16:42:26.122285Z","iopub.execute_input":"2025-03-19T16:42:26.122637Z","iopub.status.idle":"2025-03-19T16:42:26.146762Z","shell.execute_reply.started":"2025-03-19T16:42:26.122603Z","shell.execute_reply":"2025-03-19T16:42:26.145960Z"}},"outputs":[{"name":"stdout","text":"<sos> what is your name? <eos>\n","output_type":"stream"},{"execution_count":81,"output_type":"execute_result","data":{"text/plain":"'<sos> wie heit dein <eos>'"},"metadata":{}}],"execution_count":81},{"cell_type":"code","source":"translate(model, \"<sos> who is the king <eos>\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T16:43:41.432405Z","iopub.execute_input":"2025-03-19T16:43:41.432805Z","iopub.status.idle":"2025-03-19T16:43:41.457957Z","shell.execute_reply.started":"2025-03-19T16:43:41.432772Z","shell.execute_reply":"2025-03-19T16:43:41.457077Z"}},"outputs":[{"name":"stdout","text":"<sos> who is the king <eos>\n","output_type":"stream"},{"execution_count":84,"output_type":"execute_result","data":{"text/plain":"'<sos> wer ist der konig <eos> <eos>'"},"metadata":{}}],"execution_count":84},{"cell_type":"code","source":"translate(model, \"<sos> next <eos>\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T16:44:03.940901Z","iopub.execute_input":"2025-03-19T16:44:03.941223Z","iopub.status.idle":"2025-03-19T16:44:03.964621Z","shell.execute_reply.started":"2025-03-19T16:44:03.941195Z","shell.execute_reply":"2025-03-19T16:44:03.963654Z"}},"outputs":[{"name":"stdout","text":"<sos> next <eos>\n","output_type":"stream"},{"execution_count":85,"output_type":"execute_result","data":{"text/plain":"'<sos> nachste mal <eos> <eos>'"},"metadata":{}}],"execution_count":85},{"cell_type":"code","source":"translate(model, \"<sos> what is the time <eos>\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T16:44:35.778125Z","iopub.execute_input":"2025-03-19T16:44:35.778416Z","iopub.status.idle":"2025-03-19T16:44:35.805725Z","shell.execute_reply.started":"2025-03-19T16:44:35.778393Z","shell.execute_reply":"2025-03-19T16:44:35.804664Z"}},"outputs":[{"name":"stdout","text":"<sos> what is the time <eos>\n","output_type":"stream"},{"execution_count":86,"output_type":"execute_result","data":{"text/plain":"'<sos> wie viel ist zeit zeit zeit'"},"metadata":{}}],"execution_count":86},{"cell_type":"code","source":"translate(model, \"<sos> when should i come <eos>\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T16:45:04.895217Z","iopub.execute_input":"2025-03-19T16:45:04.895551Z","iopub.status.idle":"2025-03-19T16:45:04.922193Z","shell.execute_reply.started":"2025-03-19T16:45:04.895520Z","shell.execute_reply":"2025-03-19T16:45:04.921209Z"}},"outputs":[{"name":"stdout","text":"<sos> when should i come <eos>\n","output_type":"stream"},{"execution_count":87,"output_type":"execute_result","data":{"text/plain":"'<sos> wann kommen kommen kommen kommen'"},"metadata":{}}],"execution_count":87},{"cell_type":"code","source":"translate(model, \"<sos> she is his wife <eos>\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T16:45:27.697480Z","iopub.execute_input":"2025-03-19T16:45:27.697787Z","iopub.status.idle":"2025-03-19T16:45:27.725994Z","shell.execute_reply.started":"2025-03-19T16:45:27.697764Z","shell.execute_reply":"2025-03-19T16:45:27.725142Z"}},"outputs":[{"name":"stdout","text":"<sos> she is his wife <eos>\n","output_type":"stream"},{"execution_count":88,"output_type":"execute_result","data":{"text/plain":"'<sos> sie ist ist frau <eos>'"},"metadata":{}}],"execution_count":88},{"cell_type":"code","source":"translate(model, \"<sos> I am the one <eos>\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T16:45:49.634377Z","iopub.execute_input":"2025-03-19T16:45:49.634733Z","iopub.status.idle":"2025-03-19T16:45:49.660123Z","shell.execute_reply.started":"2025-03-19T16:45:49.634702Z","shell.execute_reply":"2025-03-19T16:45:49.659383Z"}},"outputs":[{"name":"stdout","text":"<sos> I am the one <eos>\n","output_type":"stream"},{"execution_count":89,"output_type":"execute_result","data":{"text/plain":"'<sos> ich bin ist <eos>'"},"metadata":{}}],"execution_count":89}]}